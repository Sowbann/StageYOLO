# ğŸ“Š But du stage

Ce repository contient les fichiers et scripts associÃ©s Ã  l'utilisation de plusieurs datasets, destinÃ©s Ã  la classification des trous de route et des dÃ©chets.

Nous utilisons **Ultralytics YOLO** pour la classification :  
ğŸ‘‰ https://github.com/ultralytics/ultralytics

---

## ğŸ“ Contenu

Les datasets utilisÃ©s (vous n'etes pas obligÃ© de les telecharger un a un):

- **TACO** (dataset de dÃ©chets) : https://github.com/pedropro/TACO
- **RDD_SPLIT** (dataset de routes abÃ®mÃ©es) : https://www.kaggle.com/datasets/aliabdelmenam/rdd-2022
- **augmenteTACO** (dataset de dÃ©chets, basÃ© sur TACO augmentÃ© grÃ¢ce Ã  `augmentation.py`)

---

## Utilisation

Selon le training que vous voulez effectuÃ©, modifier le fichier pour mettre les parametres(model a utiliser, nombre d'epoch, etc...) que vous souhaitez dans script/ :
train_road.py pour les routes
train_waste.py pour les dechets

Pour lancer un training, un scrit slurm est disponible dans script/train.slurm
Il vous faut decommentÃ© ce que vous voulez faire et changer les liens des fichiers selon votre architecture 

---

## Resultat 

Un fichier resultat est disponible avec son model et le resultat de son entrainement
Lorsqu'il y a ecrit yy_versionXX, cela veut dire que c'est la version du model yy avec XX nombre d'epoch

Vous pouvez aussi retrouver l'entieretÃ© de l'entrainement dans runs/anciens/ pour chaque model 

---

## ğŸ“¥ TÃ©lÃ©chargement des datasets

Le dataset complet est disponible en tÃ©lÃ©chargement via le lien suivant disponible jusqu'au 13/07:

ğŸ‘‰ [TÃ©lÃ©charger datasets](https://exemple.com/chemin/vers/le/dataset.zip)

Une fois tÃ©lÃ©chargÃ©, vous pouvez l'extraire avec la commande suivante :

```bash
unzip datasets.zip -d ./datasets